{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0d19a31",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Text Data Processing\n",
    "\n",
    "In this assignment we are writing the following 2 functions for Text Data Processing\n",
    "\n",
    "<ul>\n",
    "    <li>\n",
    "        <b>preprocess:</b> Function takes in a pandas.Series() of a corpus of text data as an argument. This function should output an indexed vocabulary and preprocessed tokens.\n",
    "    </li>\n",
    "    <li>\n",
    "        <b>encode():</b> Function that takes in two arguments: 1) a pandas.Series() (or the preprocessed token outputs of the preprocess() function), and 2) a specified encoding method. These encoding methods must include Bag-of-Words, TF-IDF, and Word2Vec. \n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c7ebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install nltk\n",
    "!pip install contractions\n",
    "!pip install inflect\n",
    "!pip install scikit-learn \n",
    "!pip install gensim\n",
    "!pip uninstall -y tensorflow\n",
    "!pip install torch\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49afd262-2b5f-4524-9099-86cb2e2cff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa69683-bf75-4c4b-98ea-c42b4a4c3c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Specify the model\n",
    "model_id = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "sentiment_pipe = pipeline(\"sentiment-analysis\", model=model_id)\n",
    "print(sentiment_pipe('I hate you'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6583f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Display Properties\n",
    "from IPython.display import display, HTML\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "pd.set_option('display.precision', 2)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5be5ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import inflect\n",
    "import contractions\n",
    "from data_pipeline import Text_Pipeline\n",
    "\n",
    "# Download the various \n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Initialize various tools\n",
    "text_pipeline = Text_Pipeline('CONVERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf4c668",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "CORPUS = [\n",
    "    \"The quick brown fox jumps over the lazy dog\",\n",
    "    \"A king's strength also includes his allies\",\n",
    "    \"History is written by the victors\",\n",
    "    \"An apple a day keeps the doctor away\",\n",
    "    \"Nothing happens until something moves\",\n",
    "    \"The 10,000,303 striped bats    aren't hanging on their feet for best.\"\n",
    "    ]\n",
    "\n",
    "# Create a Pandas series \n",
    "s = pd.Series(CORPUS) \n",
    "\n",
    "# Obtain pre processed series\n",
    "preprocessed_series = text_pipeline.preprocess(s)\n",
    "print(preprocessed_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b2d1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get matrix using BOW\n",
    "matrix, column_names = text_pipeline.encode(preprocessed_series, 'BOW')\n",
    "\n",
    "result = pd.DataFrame(\n",
    "    data=matrix.toarray(), \n",
    "    index=preprocessed_series.values, \n",
    "    columns=column_names\n",
    ")\n",
    "\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfcc7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get matrix using TF-IDF\n",
    "matrix, column_names = text_pipeline.encode(preprocessed_series, 'TFIDF')\n",
    "\n",
    "result = pd.DataFrame(\n",
    "    data=matrix.toarray(), \n",
    "    index=preprocessed_series.values, \n",
    "    columns=column_names\n",
    ")\n",
    "\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2def9470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get matrix using Word to Vector\n",
    "matrix = text_pipeline.encode(preprocessed_series, 'WordToVec')\n",
    "\n",
    "result = pd.DataFrame(\n",
    "    data=matrix.vectors, \n",
    "    index=matrix.key_to_index.keys()\n",
    ")\n",
    "\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75015e0-e21c-439f-8ffc-6970fd82610b",
   "metadata": {},
   "source": [
    "We will now apply a model to it using Large Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83a37e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text):\n",
    "    #sentiment_analyzer = pipeline('sentiment-analysis', model=model_id)\n",
    "    result = sentiment_pipe(text)\n",
    "    return result[0]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee7923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Analyze the sentiment of a few sentences\n",
    "amazon_reviews = [\n",
    "    \"My kiddos liked it!\",\n",
    "    \"Amazon, please buy the show! I'm hooked!\",\n",
    "]\n",
    "\n",
    "#amazon_reviews = df1['text'].values\n",
    "\n",
    "# Analyze sentiment for each news headline\n",
    "sentiments = [analyze_sentiment(review) for review in amazon_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8142c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581f5e53-c2fd-4b0b-8d1b-567b933b5416",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(amazon_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b97d29-687e-457c-b647-c1dc84577eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(preprocessed_series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb59bc9e-8f0b-46ab-8c52-9e568c1e6269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

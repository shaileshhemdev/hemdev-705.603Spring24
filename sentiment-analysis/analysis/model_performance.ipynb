{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "208f5e3a-0597-481e-8430-c0c7daa10890",
   "metadata": {},
   "source": [
    "# Model Performance\n",
    "\n",
    "We will use this notebook to make use of the various classes created for ETL, Text Processing, Model and Metrics to measure the performance of various models. We have tried the following models\n",
    "\n",
    "<ul>\n",
    "    <li>\n",
    "        <b>Twitter:</b> TBD\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f72f7a19-5987-4201-9eac-7079293302a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (24.0)\n",
      "Requirement already satisfied: nltk in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (3.7)\n",
      "Requirement already satisfied: click in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: contractions in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: anyascii in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
      "Requirement already satisfied: pyahocorasick in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n",
      "Requirement already satisfied: inflect in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (7.2.0)\n",
      "Requirement already satisfied: more-itertools in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from inflect) (10.2.0)\n",
      "Requirement already satisfied: typeguard>=4.0.1 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from inflect) (4.2.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from inflect) (4.11.0)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from typeguard>=4.0.1->inflect) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=3.6->typeguard>=4.0.1->inflect) (3.8.0)\n",
      "Requirement already satisfied: numpy in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (1.24.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: gensim in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (4.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from gensim) (1.24.4)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from gensim) (1.9.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from gensim) (5.2.1)\n",
      "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: networkx in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: fsspec in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from sympy->torch) (1.2.1)\n",
      "Requirement already satisfied: transformers in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (4.40.0)\n",
      "Requirement already satisfied: filelock in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shaileshhemdev/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2022.9.24)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install nltk\n",
    "!pip install contractions\n",
    "!pip install inflect\n",
    "!pip install numpy \n",
    "!pip install scikit-learn \n",
    "!pip install gensim\n",
    "!pip uninstall -y tensorflow\n",
    "!pip install torch\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dd9304d-4a0c-4e38-86ab-2ec02f5f2d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the notebook to import modules from relative paths\n",
    "import os, sys\n",
    "\n",
    "#'/home/user/example/parent/child'\n",
    "current_path = os.path.abspath('.')\n",
    "\n",
    "#'/home/user/example/parent'\n",
    "parent_path = os.path.dirname(current_path)\n",
    "\n",
    "sys.path.append(parent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34637e7a-27da-4597-b492-94c80a714f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from model import Sentiment_Analysis_Model\n",
    "\n",
    "twitter_model = Sentiment_Analysis_Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e06b1b4-fe22-41e4-992e-118c4aed32eb",
   "metadata": {},
   "source": [
    "First provide the base directory where you have the Amazon Reviews Dataset in CSV format along with the exact file name. We will make use of the <b>ETL_Pipeline</b> class to load this raw file and perform the transformations we have deemed to be needed for the model. We will also save the transformed file since it will help us eventually speed the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1218e5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_title</th>\n",
       "      <th>text</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>main_category</th>\n",
       "      <th>categories</th>\n",
       "      <th>tags</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Amazon, please buy the show! I'm hooked!</td>\n",
       "      <td>0</td>\n",
       "      <td>Prime Video</td>\n",
       "      <td>Suspense  Drama</td>\n",
       "      <td>Nudity violence substance use alcohol use smok...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>My Kiddos LOVE this show!!</td>\n",
       "      <td>0</td>\n",
       "      <td>Prime Video</td>\n",
       "      <td>Kids</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Some decent moments...but...</td>\n",
       "      <td>Annabella Sciorra did her character justice wi...</td>\n",
       "      <td>0</td>\n",
       "      <td>Prime Video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Violence substance use foul language sexual co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Decent Depiction of Lower-Functioning Autism, ...</td>\n",
       "      <td>...there should be more of a range of characte...</td>\n",
       "      <td>1</td>\n",
       "      <td>Prime Video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Violence alcohol use foul language sexual content</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>What Love Is...</td>\n",
       "      <td>...isn't always how you expect it to be, but w...</td>\n",
       "      <td>0</td>\n",
       "      <td>Prime Video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                       review_title  \\\n",
       "0     5.0                                         Five Stars   \n",
       "1     5.0                                         Five Stars   \n",
       "2     3.0                       Some decent moments...but...   \n",
       "3     4.0  Decent Depiction of Lower-Functioning Autism, ...   \n",
       "4     5.0                                    What Love Is...   \n",
       "\n",
       "                                                text  helpful_vote  \\\n",
       "0           Amazon, please buy the show! I'm hooked!             0   \n",
       "1                         My Kiddos LOVE this show!!             0   \n",
       "2  Annabella Sciorra did her character justice wi...             0   \n",
       "3  ...there should be more of a range of characte...             1   \n",
       "4  ...isn't always how you expect it to be, but w...             0   \n",
       "\n",
       "  main_category       categories  \\\n",
       "0   Prime Video  Suspense  Drama   \n",
       "1   Prime Video             Kids   \n",
       "2   Prime Video              NaN   \n",
       "3   Prime Video              NaN   \n",
       "4   Prime Video              NaN   \n",
       "\n",
       "                                                tags  class  \n",
       "0  Nudity violence substance use alcohol use smok...      2  \n",
       "1                                                NaN      2  \n",
       "2  Violence substance use foul language sexual co...      1  \n",
       "3  Violence alcohol use foul language sexual content      2  \n",
       "4                                                NaN      2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from etl_pipeline import ETL_Pipeline \n",
    "\n",
    "# Initialize the reviews\n",
    "base_dir = \"/Users/shaileshhemdev/ai/ai-enabledsystems/workspace/\"\n",
    "source_file = \"amazon_movie_reviews.csv\"\n",
    "path = base_dir + source_file\n",
    "\n",
    "dp = ETL_Pipeline(base_dir)\n",
    "transformed_df = dp.process(source_file)\n",
    "transformed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc737b9-54c6-4599-8799-0877663a2e4c",
   "metadata": {},
   "source": [
    "Load the dataset to get training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ceee2ed-1a90-417d-be80-a5ea6d883740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fold = 4 yields Training Dataset with 800000 records and Testing with 200000 records.\n"
     ]
    }
   ],
   "source": [
    "from dataset import Sentiment_Analysis_Dataset\n",
    "import random\n",
    "\n",
    "# Initialize the Sentiment Analysis Dataset\n",
    "dataset = Sentiment_Analysis_Dataset(transformed_df, 'class')\n",
    "\n",
    "# Get a random fold\n",
    "random_fold = random.randint(0, 4)\n",
    "\n",
    "# Get Training and Test datasets for this fold\n",
    "train = dataset.get_training_dataset(random_fold)\n",
    "test = dataset.get_testing_dataset(random_fold)\n",
    "\n",
    "# Print the sizes to see if you get a good split\n",
    "print(f\" Fold = {random_fold+1} yields Training Dataset with {len(train[0])} records and Testing with {len(test[0])} records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87a23063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Display Properties\n",
    "from IPython.display import display, HTML\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "pd.set_option('display.precision', 2)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "sns.set(style=\"ticks\", color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9899ba3-bede-4189-b0d4-23e39a085e84",
   "metadata": {},
   "source": [
    "We will now verify the Model results first using a model run done before with 76000 results which took several hours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3a21f65-3c99-44ba-859d-30ffd719ebae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>class</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon, please buy the show! I'm hooked!</td>\n",
       "      <td>5.000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My Kiddos LOVE this show!!</td>\n",
       "      <td>5.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annabella Sciorra did her character justice wi...</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>...there should be more of a range of characte...</td>\n",
       "      <td>4.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>...isn't always how you expect it to be, but w...</td>\n",
       "      <td>5.000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         text                         rating  class  predicted_class\n",
       "0           Amazon, please buy the show! I'm hooked!  5.000     2           1       \n",
       "1                         My Kiddos LOVE this show!!  5.000     2           2       \n",
       "2  Annabella Sciorra did her character justice wi...  3.000     1           1       \n",
       "3  ...there should be more of a range of characte...  4.000     2           2       \n",
       "4  ...isn't always how you expect it to be, but w...  5.000     2           1       "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_run_df = pd.read_csv(\"../sentiments-twitter-model.csv\")\n",
    "model_run_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59443760-d37f-44ba-9277-7ce9d6f84480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import Metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "metrics = Metrics()\n",
    "\n",
    "y_vals = model_run_df[\"class\"].values\n",
    "y_pred = model_run_df[\"predicted_class\"].values\n",
    "\n",
    "acc, acc_bal, prec, recall, f1 = metrics.run(y_vals, y_pred)\n",
    "accs, acc_bals, precs, recalls, f1s = [], [], [], [], []\n",
    "\n",
    "accs += [acc]\n",
    "acc_bals += [acc_bal]\n",
    "precs += [prec]\n",
    "recalls += [recall]\n",
    "f1s += [f1]\n",
    "\n",
    "metrics.generate_report(accs, acc_bals, precs, recalls, f1s, ['twitter-roberta-base'],'../results/model-run1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec96187-2ed0-444b-b0c4-7a3996952c80",
   "metadata": {},
   "source": [
    "Now we will run it in a loop to generate results with samples extracted from each "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ce5e46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I liked the premise but this movie was exhaustingly slower than it  needed to be. By the time it was at the end I didn't care what was happening.\n",
      "Upfront: it's missing the sweet, innocent, magical and heartwarming charm of &#34;The Fellowship.&#34; I saw all those familiar places and familiar faces: Gandalf, Bag End, The Shire, Elrond, Rivendell. I missed Strider and the original hobbits. I missed the danger they were running from, the reason for their journey. The tone of this film is different, which is perfectly fine, I just wasn't really expecting that difference. It was harder to reconcile in this film. In the 2nd and 3rd films, when we get away from all the old and familiar and into the new and different they were much easier to get into and enjoy on their own.<br /><br />Everyone complains that it's long, but I don't have a problem with length if it fleshes out the story. OTOH, contriving shots to stuff into already over-extended battle/fight scenes definitely adds to the weight and sluggish speed of the film with adding anything crucial to the story. They were glaringly obvious, jarring and they took me out of the story every time, which is why this is 3 stars instead of 4 OTOH, I think every second of exposition and character development was necessary. There were so many dwarves and so much background information and I think both were delivered pretty well.\n",
      "Though this film got rave reviews I found it boring.\n",
      "The story and the acting\n",
      "One of the greatest TV series to come a long in awhile. Leverage is classy, elegant, humorous and action packed no matter what season this show is the best of all time.<br />So much fun to watch.\n",
      "Need I say more, this was the best, I cried about at the half way point because of knowing the ending.  It was great, one of the best movies I have seen in a long time.\n",
      "Love Goldblum! Good story & cast.\n",
      "Great deal for all 4 movies! I will scream all I want and people will hear me in space!<br /><br />Blu-ray disks, all 4 movies: Aliens 1979/2003-Aliens 1986/1991-Alien 3 1992/2003-Alien Resurrection 1997/2003, carboard sleeve, 8 versions<br /><br />Special Features: MU-TH-UR Mode Interactive Experience wit datastream of production notes and historical facts, all movies contain full length audio commentary, behind the scenes featurettes, 12k photos and artwork stills,  isolated scores w/ alternate and unused cues, archival documentaries, test footage, tv specials, multi-angle studies\n",
      "The best out of all the Predator sequels. Keeps thou on edge.\n",
      "Never thought much about training to do this dangerous work. We need people who are willing to climb poles and fix electrical lines that have fallen or put new ones up. I thought it was good.\n",
      "Great Price for a Great Show!\n",
      "Good acting, good action. Sad.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# List of classifiers\n",
    "classifiers = ['twitter-roberta-base']\n",
    "\n",
    "for classifier in classifiers:\n",
    "    for fold in range(0,5):\n",
    "        # Initialize Metric Arrays \n",
    "        accs, acc_bals, precs, recalls, f1s  = [], [], [], [], []\n",
    "\n",
    "        # Get the training, validation and test datasets\n",
    "        X_train, y_train = dataset.get_training_dataset(fold)\n",
    "        X_test, y_test = dataset.get_testing_dataset(fold)\n",
    "        X_val, y_val = dataset.get_validation_dataset(fold)\n",
    "        \n",
    "        # Get random samples from train, val and test \n",
    "        train_sublist = random.sample(range(len(X_train)), 200)\n",
    "        test_sublist = random.sample(range(len(X_test)), 200)\n",
    "        val_sublist = random.sample(range(len(X_val)), 200)\n",
    "        \n",
    "        # Obtain the metrics for training subset\n",
    "        X = X_train[train_sublist][:,2]\n",
    "        y = y_train[train_sublist]\n",
    "\n",
    "        acc, acc_bal, prec, recall, f1 = twitter_model.test(X, y)\n",
    "    \n",
    "        # Collect the metrics \n",
    "        accs += [acc]\n",
    "        acc_bals += [acc_bal]\n",
    "        precs += [prec]\n",
    "        recalls += [recall]\n",
    "        f1s += [f1]\n",
    "        \n",
    "        # Obtain the metrics for testing subset\n",
    "        X = X_test[test_sublist][:,2]\n",
    "        y = y_test[test_sublist]\n",
    "\n",
    "        acc, acc_bal, prec, recall, f1 = twitter_model.test(X, y)\n",
    "    \n",
    "        # Collect the metrics \n",
    "        accs += [acc]\n",
    "        acc_bals += [acc_bal]\n",
    "        precs += [prec]\n",
    "        recalls += [recall]\n",
    "        f1s += [f1]\n",
    "        \n",
    "        # Obtain the metrics for validation subset\n",
    "        X = X_val[val_sublist][:,2]\n",
    "        y = y_val[val_sublist]\n",
    "\n",
    "        acc, acc_bal, prec, recall, f1 = twitter_model.test(X, y)\n",
    "    \n",
    "        # Collect the metrics \n",
    "        accs += [acc]\n",
    "        acc_bals += [acc_bal]\n",
    "        precs += [prec]\n",
    "        recalls += [recall]\n",
    "        f1s += [f1]\n",
    "\n",
    "        # Generate the Report\n",
    "        metrics.generate_report(accs, acc_bals, precs, recalls, f1s, ['twitter-roberta-base'],'../results/model-run' + str(fold) + '.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5ffc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

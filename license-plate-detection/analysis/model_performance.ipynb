{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17c14ed6",
   "metadata": {},
   "source": [
    "# Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cdd2c9",
   "metadata": {},
   "source": [
    "We will analyze the 2 Yolo models supplied and compare their performance\n",
    "\n",
    "<b>Pre-requisites</b>: The notebook assumes that you have ffmpeg installed on the container or host where this notebook is running. If this is running on a container then make sure the container's docker file has the following \n",
    "\n",
    "apt-get update -qq && apt-get install ffmpeg -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58780f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy \n",
    "!pip install matplotlib\n",
    "!pip uninstall -y opencv-python-headless\n",
    "!pip uninstall -y opencv-python\n",
    "!pip uninstall -y cv2\n",
    "!pip uninstall -y pylabel\n",
    "!pip install pylabel\n",
    "!pip install opencv-python-headless\n",
    "!pip install pytesseract\n",
    "!pip install ffmpeg-python\n",
    "!pip install pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04de9f6",
   "metadata": {},
   "source": [
    "We first do a setup here to enable this notebook to access classes in the parent directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f0cfd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the notebook to import modules from relative paths\n",
    "import os, sys\n",
    "\n",
    "#'/home/user/example/parent/child'\n",
    "current_path = os.path.abspath('.')\n",
    "\n",
    "#'/home/user/example/parent'\n",
    "parent_path = os.path.dirname(current_path)\n",
    "\n",
    "sys.path.append(parent_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eae898",
   "metadata": {},
   "source": [
    "We have already loaded the images from the video stream, cropped them and stored the cropped images in an external volume mapped to the current docker file system. In this notebook we will make use of the Object_Detection_Dataset to get a testing dataset to determine which model is performing better. \n",
    "\n",
    "For context we have 2 models with the following files\n",
    "\n",
    "<ul>\n",
    "    <li>lpr-yolov3.cfg and lpr-yolov3.weights</li>\n",
    "    <li>lpr-yolov3-tiny.cfg and lpr-yolov3-tiny.weights</li>\n",
    "</ul>\n",
    "\n",
    "All the images essentially show 2 license plates clearly and so the model that detects the more plates is likely to have higher precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58058eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import cv2 as cv\n",
    "from dataset import Object_Detection_Dataset\n",
    "\n",
    "folds = 10\n",
    "dataset = Object_Detection_Dataset(data_folder='/workspace/shared-data/license-plates/alpr-images/cropped/',n_folds=folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a08772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Object_Detection_Model\n",
    "\n",
    "model1 = Object_Detection_Model(cfg_file= \"lpr-yolov3.cfg\", weights_file='lpr-yolov3.weights', base_dir='/workspace/shared-data/license-plates/alpr-images/')\n",
    "model2 = Object_Detection_Model(cfg_file= \"lpr-yolov3-tiny.cfg\", weights_file='lpr-yolov3-tiny.weights', base_dir='/workspace/shared-data/license-plates/alpr-images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ede301cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Maintain list for scores by each fold\n",
    "precision1_scores = []\n",
    "precision2_scores = []\n",
    "\n",
    "for fold in range(folds):\n",
    "    # Let's keep count of TP\n",
    "    tp1 = 0\n",
    "    tp2 = 0\n",
    "\n",
    "    # Get the test data\n",
    "    test_data = dataset.get_testing_dataset(fold)\n",
    "    \n",
    "    # On an average each image is showing 2 cars with their license plates visible - so total is twice as the number of images\n",
    "    total_count = len(test_data) * 2\n",
    "    print(fold)\n",
    "    for img_file in test_data:\n",
    "        results1 = model1.test(img_file,list())\n",
    "        results2 = model2.test(img_file,list())\n",
    "    \n",
    "        tp1 += len(results1)\n",
    "        tp2 += len(results2)\n",
    "    \n",
    "    precision1 = tp1 / total_count\n",
    "    precision2 = tp2 / total_count\n",
    "        \n",
    "    precision1_scores += [precision1]\n",
    "    precision2_scores += [precision2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b9d9f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>K-Fold</th>\n",
       "      <th>Model 1 Precision</th>\n",
       "      <th>Model 2 Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.000</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.000</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.000</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.000</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.000</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.000</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.000</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.000</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Display Properties\n",
    "from IPython.display import display, HTML\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "pd.set_option('display.precision', 2)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "model_stats = np.column_stack((range(1,folds+1), precision1_scores, precision2_scores))\n",
    "model_stats_df = pd.DataFrame(model_stats, columns = ['K-Fold','Model 1 Precision','Model 2 Precision'])\n",
    "display(HTML(model_stats_df.to_html())) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd494fc",
   "metadata": {},
   "source": [
    "From the above model, it looks like Model 1 is doing slightly better in terms of its precisions as it is measured using number of objects detected with a confidence score greater than 0.5. Given that we don't have currently ground truths available the above is not able to detect False Positives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfc4c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a4059a4",
   "metadata": {},
   "source": [
    "# Object Detection - Graphical Degrading and Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e31d050",
   "metadata": {},
   "source": [
    "## Steps for Part 1 - Graphical Degrading\n",
    "1. Download zip code from assignment repository\n",
    "1. Download the yolov3.weights from the readme in the github repository (This file is too big for github versioning)\n",
    "1. Edit/Create an git \"exclude\" file in the main portfolio directory \".git/info\".  Add \"yolov3.weights\" on a line by itself.  This avoids a git push failure due to the size of the file.\n",
    "1. Fill in the missing code in this notebook  (You will need the working code examples to do the next step)\n",
    "1. Create a python class that allows the following\n",
    "   - Reads in the image\n",
    "   - Create a loop that alters individual changes of the items below to determine names of identified objects and their confidence (down to when the object detetion is lost).  Remember to reset the image through each pass as they are not iterative.\n",
    "     - size\n",
    "     - rotation\n",
    "     - noise (of your choice)\n",
    "   - Graph the results\n",
    "   \n",
    "## Steps for Part 2 - Object Detection\n",
    "1.  Generate a web interface python script that ingests a POST command of a picture Use [postman](https://www.postman.com/) to generate the post with picture of your choice.\n",
    "1.  Returns the items detected and the assocated confidence\n",
    "1.  Add to your python class above to offer this capability\n",
    "1.  Test web interface locally\n",
    "1.  Create a Dockerfile and build the image\n",
    "1.  Test the Dockerfile locally\n",
    "1.  Push notebook, python script, readme, etc to your github portfolio (since you are in the right location locally you just need to do a push at the main directory of the portfolio (after git add * and git commit -m \" comment)\n",
    "1.  Push locally built and test docker image to your docker hub portfolio.  Manually add to docker readme.\n",
    "1.  Submit the two links (github Assignment5 directory and docker hub) via text submission to Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6762f7c",
   "metadata": {},
   "source": [
    "## Initial Start\n",
    "* Load Libraries (Need to install wandb and cv2 - see below)\n",
    "* plot_cv_image( img ) allows output of image within a notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2810830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "# !pip install opencv-python-headless\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "# !pip install wandb\n",
    "from wandb import Classes\n",
    "\n",
    "\n",
    "def plot_cv_img(input_image):     \n",
    "    \"\"\"     \n",
    "    Converts an image from BGR to RGB and plots     \n",
    "    \"\"\"   \n",
    "    # change color channels order for matplotlib     \n",
    "    plt.imshow(cv.cvtColor(input_image, cv.COLOR_BGR2RGB))          \n",
    "\n",
    "    # For easier view, turn off axis around image     \n",
    "    plt.axis('off')  \n",
    "    # Must save prior to show - for show clears the image!\n",
    "    #plt.savefig(\"DetectionOutput.jpg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc56974",
   "metadata": {},
   "source": [
    "## Load Yolo Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef15ff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load yolo\n",
    "net = cv.dnn.readNet(\"yolov3.weights\",  #note weights to too big for github must save within readme\n",
    "                     \"yolov3.cfg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cf9edf",
   "metadata": {},
   "source": [
    "## Identify the number of layers in the model and their names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955daeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = net.getLayerNames()\n",
    "print(len(ln), ln)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ee0551",
   "metadata": {},
   "source": [
    "## Read in and print out the categories for Yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da157a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "with open(\"coco.names\", 'r') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4fadc8",
   "metadata": {},
   "source": [
    "## Read in an image and output its dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20fe8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"pictures/bermuda.jpg\")\n",
    "print(\"Original Shape: \", img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf0e2c2",
   "metadata": {},
   "source": [
    "## Resize the image and output its dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953d5870",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.( )  # Add code to resize\n",
    "height, width, channel = img.shape\n",
    "print(\"Resized Shape: \", img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00b9b9f",
   "metadata": {},
   "source": [
    "## Rotate the image using cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9508d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotate\n",
    "rotated_img = cv( )  # add code to rotate\n",
    "plot_cv_img(rotated_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b9166b",
   "metadata": {},
   "source": [
    "## Rotate the image using scipy (might have to install if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ede01bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotate\n",
    "from scipy import ndimage\n",
    "rotated_img = ndimage ( ) # add code to rotate\n",
    "plot_cv_img(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7388d9d7",
   "metadata": {},
   "source": [
    "## Add Salt and Pepper Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cb7a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add salt and pepper noise\n",
    "from skimage.util import random_noise\n",
    "# Add salt-and-pepper noise to the image.\n",
    "\n",
    "noise_img = random_noise(  )  # add code to add salt and pepper noise\n",
    " \n",
    "# The above function returns a floating-point image\n",
    "# on the range [0, 1], thus we changed it to 'uint8'\n",
    "# and from [0,255]\n",
    "\n",
    "noise_img = np.array(255*noise_img, dtype = 'uint8')\n",
    "\n",
    "plot_cv_img(noise_img )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d992789",
   "metadata": {},
   "source": [
    "## Add Gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b43446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "gauss = np.random.normal( ) # add code  to add gaussian noise\n",
    "gauss = gauss.reshape(img.shape[0],img.shape[1],img.shape[2]).astype('uint8')\n",
    "\n",
    "# Add the Gaussian noise to the image\n",
    "img_gauss = cv.  # Add the noise to the image\n",
    "# Display the image\n",
    "plot_cv_img(img_gauss )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de63e38",
   "metadata": {},
   "source": [
    "## Add Speckle Noise with color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7965635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Speckle Noise\n",
    "import numpy as np\n",
    " \n",
    "img = cv.imread('pictures/bermuda.jpg')\n",
    " \n",
    "gauss = np.random.normal( )  # add code to add speckle noise\n",
    "gauss = gauss.reshape(img.shape[0],img.shape[1],img.shape[2]).astype('uint8')\n",
    "speckle_img = \n",
    "plot_cv_img(speckle_img )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf443c83",
   "metadata": {},
   "source": [
    "## Set up layers and colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e572e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = net.getLayerNames()\n",
    "output_layer = [layer_name[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39471c8",
   "metadata": {},
   "source": [
    "## Fire up Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068b6f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#note - 0.00392 = 1/250   416 is a standard square for yolo\n",
    "blob = cv.dnn.blobFromImage(\n",
    "    img,   )  # Fill in other fields to create image compatible with cv\n",
    "\n",
    "#detect objects\n",
    "net.setInput(blob)\n",
    "outs = net.forward(output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06179bee",
   "metadata": {},
   "source": [
    "## Set up image on screen  (all done for you)\n",
    "* Note how to extract the identified objects and their assocated confidence.  You need that for part 2 of this assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b38514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing Information on the screen\n",
    "class_ids = []\n",
    "confidences = []\n",
    "boxes = []\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5:\n",
    "            # Object detection\n",
    "            center_x = int(detection[0] * width)\n",
    "            center_y = int(detection[1] * height)\n",
    "            w = int(detection[2] * width)\n",
    "            h = int(detection[3] * height)\n",
    "            # cv.circle(img, (center_x, center_y), 10, (0, 255, 0), 2 )\n",
    "            # Reactangle Cordinate\n",
    "            x = int(center_x - w/2)\n",
    "            y = int(center_y - h/2)\n",
    "            boxes.append([x, y, w, h])\n",
    "            confidences.append(float(confidence))\n",
    "            class_ids.append(class_id)\n",
    "           \n",
    "print(\"Type: \", type(class_ids))\n",
    "\n",
    "indexes = cv.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "print(indexes)\n",
    "\n",
    "font = cv.FONT_HERSHEY_PLAIN\n",
    "for i in range(len(boxes)):\n",
    "    if i in indexes:\n",
    "        x, y, w, h = boxes[i]\n",
    "        label = str(classes[class_ids[i]])\n",
    "        print(f'Object: {label} with confidence of {confidences[i]:.2f}')\n",
    "        color = colors[i]\n",
    "        cv.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "        cv.putText(img, label, (x, y + 30), font, 3, color, 3)\n",
    "\n",
    "plot_cv_img(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76fb94e",
   "metadata": {},
   "source": [
    "# Summary\n",
    "### Note the point at which the resize of the image degrades the image where the model can no longer detect the objects.  Graph the degradation confidence.\n",
    "### Note the point at which the Gaussian noise and the salt and peper noise degrades the image where the model can no longer detect the objects.  Graph the degradtion condifidence.\n",
    "\n",
    "### Note techniques in the model and/or image that improve the object detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c919370",
   "metadata": {},
   "source": [
    "PUT YOUR ANSWERS below which includes additional markdown cells, graph outputs and working code cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc4dd81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
